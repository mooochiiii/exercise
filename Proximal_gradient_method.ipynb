{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZJ9ygqzGi9Do8xSMAfITw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mooochiiii/exercise/blob/main/Proximal_gradient_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68jc5HlK6ACV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.multiprocessing\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import tabml.datasets\n",
        "\n",
        "\n",
        "GLOBAL_SEED = 42  # number of life\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict = tabml.datasets.download_movielen_1m()\n",
        "users, movies, ratings = df_dict[\"users\"], df_dict[\"movies\"], df_dict[\"ratings\"]\n",
        "ratings[\"Rating\"] = ratings[\"Rating\"] - 3  # rating range (-2, 2)\n",
        "train_ratings, validation_ratings = train_test_split(\n",
        "    ratings, test_size=0.1, random_state=GLOBAL_SEED\n",
        ")"
      ],
      "metadata": {
        "id": "Om82zOHc6JIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map movie id and user id to indexes.\n",
        "movie_index_by_id = {id: idx for idx, id in enumerate(movies[\"MovieID\"])}\n",
        "user_index_by_id = {id: idx for idx, id in enumerate(users[\"UserID\"])}\n",
        "\n",
        "\n",
        "class MLDataset(Dataset):\n",
        "    def __init__(self, ratings: pd.DataFrame):\n",
        "        self.ratings = ratings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        user_id = self.ratings[\"UserID\"].iloc[index]\n",
        "        movie_id = self.ratings[\"MovieID\"].iloc[index]\n",
        "        rating = self.ratings[\"Rating\"].iloc[index]\n",
        "        user_index = user_index_by_id[user_id]\n",
        "        movie_index = movie_index_by_id[movie_id]\n",
        "        return user_index, movie_index, rating\n",
        "\n",
        "\n",
        "training_data = MLDataset(train_ratings)\n",
        "validation_data = MLDataset(validation_ratings)\n",
        "batch_size = 1024\n",
        "train_dataloader = DataLoader(\n",
        "    training_data, batch_size=batch_size, shuffle=True, num_workers=10\n",
        ")\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data, batch_size=batch_size, shuffle=False, num_workers=10\n",
        ")"
      ],
      "metadata": {
        "id": "d_qpPf856Sr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jdc\n",
        "\n",
        "LR = 1\n",
        "WEIGHT_DECAY = 5e-5\n",
        "\n",
        "\n",
        "class MatrixFactorization(pl.LightningModule):\n",
        "    \"\"\"Pytorch lighting class for Matrix Factorization training.\n",
        "\n",
        "    Attributes:\n",
        "        n_users: number of users.\n",
        "        n_items: number of items.\n",
        "        n_factors: number of latent factors (or embedding size)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_users: int, n_items: int, n_factors: int = 40):\n",
        "        super().__init__()\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_factors = n_factors\n",
        "        self.user_biases = nn.Embedding(n_users, 1)\n",
        "        self.item_biases = nn.Embedding(n_items, 1)\n",
        "        self.bias = nn.Parameter(data=torch.rand(1))\n",
        "        self.user_embeddings = nn.Embedding(n_users, n_factors)\n",
        "        self.item_embeddings = nn.Embedding(n_items, n_factors)\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        \"\"\"\n",
        "        Forward pass through the model. For a single user and item, this\n",
        "        looks like:\n",
        "        bias + user_bias + item_bias + user_embeddings.dot(item_embeddings)\n",
        "\n",
        "        Arguments:\n",
        "            users: Array of user indices\n",
        "            items : Array of item indices\n",
        "        Returns:\n",
        "            preds: Predicted ratings.\n",
        "        \"\"\"\n",
        "        # select users and items from the batch\n",
        "        batch_user_embs = self.user_embeddings(users)\n",
        "        batch_item_embs = self.item_embeddings(items)\n",
        "\n",
        "        preds = torch.reshape(\n",
        "            torch.diag(\n",
        "                torch.matmul(batch_user_embs, torch.transpose(batch_item_embs, 0, 1))\n",
        "            ),\n",
        "            (-1, 1),\n",
        "        )\n",
        "        # add bias\n",
        "        preds += self.user_biases(users) + self.item_biases(items) + self.bias\n",
        "\n",
        "        return torch.clip(preds.squeeze(), min=-2, max=2)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        users, items, rating = batch\n",
        "        rating = rating.to(torch.float32)\n",
        "        output = self.forward(users, items)\n",
        "        loss = F.mse_loss(rating, output)\n",
        "        self.log(\"batch_loss\", loss)\n",
        "        return {\"loss\": loss}  # for computing avg_loss in training_epoch_end\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "zmW-oFqB6XTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for tensorboard\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "logger = TensorBoardLogger(\"mf_tb_logs\", name=f\"lr{LR}_wd{WEIGHT_DECAY}\")\n",
        "\n",
        "n_users = len(user_index_by_id)\n",
        "n_movies = len(movie_index_by_id)\n",
        "n_factors = 40\n",
        "model = MatrixFactorization(n_users=n_users, n_items=n_movies, n_factors=n_factors)\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=100, logger=logger)\n",
        "trainer.fit(model, train_dataloader, validation_dataloader)"
      ],
      "metadata": {
        "id": "ozvjWukl6d-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, train_dataloader):\n",
        "    loss = 0\n",
        "    for users, items, rating in train_dataloader:\n",
        "        pred = model(users, items)\n",
        "        loss += F.mse_loss(pred, rating)\n",
        "    RMSE = (loss / len(train_dataloader))**.5\n",
        "    return RMSE\n",
        "\n",
        "print(\"Train RMSE: {:.3f}\".format(eval_model(model, train_dataloader)))\n",
        "print(\"Validation RMSE: {:.3f}\".format(eval_model(model, validation_dataloader)))"
      ],
      "metadata": {
        "id": "FZiORsxl6s1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erk9awWK6wwn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}